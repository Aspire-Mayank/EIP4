{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day1-Definitions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aspire-Mayank/EIP4/blob/master/Session1/Assignment1/Day1_Definitions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twk7tec07TYg",
        "colab_type": "text"
      },
      "source": [
        "###Write your own definitions for:\n",
        ">1. Convolution\n",
        ">2. Filters/Kernels\n",
        ">3. Epochs\n",
        ">4. 1x1 Convolution\n",
        ">5. 3x3 Convolution\n",
        ">6. Feature Maps\n",
        ">7. Activation Function\n",
        ">8. Receptive Field"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ-BLHot7sfn",
        "colab_type": "text"
      },
      "source": [
        "###1. Convolution\n",
        "> Convolution in Computer vision define as proccess to make combination of different complex sets of output with the help of multiple number of same/different filters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8hBrxGS867X",
        "colab_type": "text"
      },
      "source": [
        "### 2. Filters/Kernals\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y16SRc6j9CK3",
        "colab_type": "text"
      },
      "source": [
        "> Filters/Kernals/channels/feature_Extractor/3X3 etc.. all are same in Computer vision as example said in class like in Music Band every instrument has Unique sound/feature which make it different and mix of all makes music."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piWG4noN--2a",
        "colab_type": "text"
      },
      "source": [
        "### 3. Epochs / Batch Size / Iteration\n",
        ">1. One Epoch is when entire Dataset is passed forward and backward through neural network once.\n",
        ">2. Number of Batch as we know we can't pass entire Dataset to Network, so will divide dataset into parts/sets/batch. Batch Size total no. of training example present in single batch.\n",
        ">3. Iteration is number of batches needed to complete one Epoch.\n",
        "[blog-](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF7mw_kdChPR",
        "colab_type": "text"
      },
      "source": [
        "###4. 1*1 (Ant Man \"Google develope-2015-Movie\")\n",
        ">1x1 is magical kernal/filter/feature_enhancer/focusing_kernal while helps in computation reduction plus feature enhancer/Amplifier, compare to expensive kernals in neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gJOoH1QE-rk",
        "colab_type": "text"
      },
      "source": [
        "###5. 3*3\n",
        "> 3*3 is symmetric smaller filter/kernal which helps lower weights and computational cost with complex feature extrator/creator. Its mask/kernal which is smallest symmetric feature extractor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dabLy93iGLXN",
        "colab_type": "text"
      },
      "source": [
        "###6. Feature Maps\n",
        "> Its extracted Features from previous layer/Input image using kernal/filter. Feature Extractor will create feature Map from input layer/Image as same size of channels present in kernal.\n",
        "Example: \n",
        "input image 28*28*3 -> 3*3*3*32 -> 26*26*32 (feature maps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtUpPWO8IgKP",
        "colab_type": "text"
      },
      "source": [
        "### 7. Activation Function\n",
        "> Activation function decides when neuron should activate or not by calculating weighted sum or bias of neuron which will help backpropgation to put non linearity/complex features network to learn.\n",
        "[Extra:Blog](https://www.geeksforgeeks.org/activation-functions-neural-networks/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l09l3WMFLMnv",
        "colab_type": "text"
      },
      "source": [
        "###8. Receptive Field\n",
        "> RF is actually where kernal looking at input feature map, and Will increase network layer/depth to increase Receptive field. Global Receptive field and local Receptive field give idea of pixel seen localy and global level respectevly. And Why we add layers to increase Global receptive field."
      ]
    }
  ]
}